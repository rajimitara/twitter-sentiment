{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentitment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOaEokctn5Y6ldZWcl+YK+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajimitara/twitter-sentiment/blob/main/twitter_sentitment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text classifier**"
      ],
      "metadata": {
        "id": "OL2OoKd7MYx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "0XNOyIkkVLjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b448668-82af-4b10-8dfd-73216b392bed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "Ix1zkXXOggJU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('https://raw.githubusercontent.com/rajimitara/twitter-sentiment/main/Corona_NLP_train.csv')"
      ],
      "metadata": {
        "id": "MAbX1IZOgn_f"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get kaggle data for twitter sentiment on vaccine\n",
        "dataset.head(20)"
      ],
      "metadata": {
        "id": "DeAbiik7VIX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "cc1b27bf-c3fd-409e-bcd6-b65973f09815"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    UserName  ScreenName                   Location     TweetAt  \\\n",
              "0       3799       48751                     London  16-03-2020   \n",
              "1       3800       48752                         UK  16-03-2020   \n",
              "2       3801       48753                  Vagabonds  16-03-2020   \n",
              "3       3802       48754                        NaN  16-03-2020   \n",
              "4       3803       48755                        NaN  16-03-2020   \n",
              "5       3804       48756  ÃT: 36.319708,-82.363649  16-03-2020   \n",
              "6       3805       48757       35.926541,-78.753267  16-03-2020   \n",
              "7       3806       48758                    Austria  16-03-2020   \n",
              "8       3807       48759            Atlanta, GA USA  16-03-2020   \n",
              "9       3808       48760           BHAVNAGAR,GUJRAT  16-03-2020   \n",
              "10      3809       48761             Makati, Manila  16-03-2020   \n",
              "11      3810       48762  Pitt Meadows, BC, Canada   16-03-2020   \n",
              "12      3811       48763                 Horningsea  16-03-2020   \n",
              "13      3812       48764                Chicago, IL  16-03-2020   \n",
              "14      3813       48765                        NaN  16-03-2020   \n",
              "15      3814       48766             Houston, Texas  16-03-2020   \n",
              "16      3815       48767               Saudi Arabia  16-03-2020   \n",
              "17      3816       48768            Ontario, Canada  16-03-2020   \n",
              "18      3817       48769              North America  16-03-2020   \n",
              "19      3818       48770                 Denver, CO  16-03-2020   \n",
              "\n",
              "                                        OriginalTweet           Sentiment  \n",
              "0   @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
              "1   advice Talk to your neighbours family to excha...            Positive  \n",
              "2   Coronavirus Australia: Woolworths to give elde...            Positive  \n",
              "3   My food stock is not the only one which is emp...            Positive  \n",
              "4   Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
              "5   As news of the regionÂs first confirmed COVID...            Positive  \n",
              "6   Cashier at grocery store was sharing his insig...            Positive  \n",
              "7   Was at the supermarket today. Didn't buy toile...             Neutral  \n",
              "8   Due to COVID-19 our retail store and classroom...            Positive  \n",
              "9   For corona prevention,we should stop to buy th...            Negative  \n",
              "10  All month there hasn't been crowding in the su...             Neutral  \n",
              "11  Due to the Covid-19 situation, we have increas...  Extremely Positive  \n",
              "12  #horningsea is a caring community. LetÂs ALL ...  Extremely Positive  \n",
              "13  Me: I don't need to stock up on food, I'll jus...            Positive  \n",
              "14  ADARA Releases COVID-19 Resource Center for Tr...            Positive  \n",
              "15  Lines at the grocery store have been unpredict...            Positive  \n",
              "16  ????? ????? ????? ????? ??\\r\\n\\r\\n?????? ?????...             Neutral  \n",
              "17  @eyeonthearctic 16MAR20 Russia consumer survei...             Neutral  \n",
              "18  Amazon Glitch Stymies Whole Foods, Fresh Groce...  Extremely Positive  \n",
              "19  For those who aren't struggling, please consid...            Positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc8a3e85-984c-4c1b-96e2-106973e363ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3804</td>\n",
              "      <td>48756</td>\n",
              "      <td>ÃT: 36.319708,-82.363649</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3805</td>\n",
              "      <td>48757</td>\n",
              "      <td>35.926541,-78.753267</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Cashier at grocery store was sharing his insig...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3806</td>\n",
              "      <td>48758</td>\n",
              "      <td>Austria</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3807</td>\n",
              "      <td>48759</td>\n",
              "      <td>Atlanta, GA USA</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3808</td>\n",
              "      <td>48760</td>\n",
              "      <td>BHAVNAGAR,GUJRAT</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>For corona prevention,we should stop to buy th...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3809</td>\n",
              "      <td>48761</td>\n",
              "      <td>Makati, Manila</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>All month there hasn't been crowding in the su...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3810</td>\n",
              "      <td>48762</td>\n",
              "      <td>Pitt Meadows, BC, Canada</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Due to the Covid-19 situation, we have increas...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3811</td>\n",
              "      <td>48763</td>\n",
              "      <td>Horningsea</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>#horningsea is a caring community. LetÂs ALL ...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3812</td>\n",
              "      <td>48764</td>\n",
              "      <td>Chicago, IL</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me: I don't need to stock up on food, I'll jus...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3813</td>\n",
              "      <td>48765</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>ADARA Releases COVID-19 Resource Center for Tr...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3814</td>\n",
              "      <td>48766</td>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Lines at the grocery store have been unpredict...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3815</td>\n",
              "      <td>48767</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>????? ????? ????? ????? ??\\r\\n\\r\\n?????? ?????...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3816</td>\n",
              "      <td>48768</td>\n",
              "      <td>Ontario, Canada</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@eyeonthearctic 16MAR20 Russia consumer survei...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3817</td>\n",
              "      <td>48769</td>\n",
              "      <td>North America</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Amazon Glitch Stymies Whole Foods, Fresh Groce...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3818</td>\n",
              "      <td>48770</td>\n",
              "      <td>Denver, CO</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>For those who aren't struggling, please consid...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc8a3e85-984c-4c1b-96e2-106973e363ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc8a3e85-984c-4c1b-96e2-106973e363ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc8a3e85-984c-4c1b-96e2-106973e363ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re"
      ],
      "metadata": {
        "id": "TGm-Sg0soLFj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "wml_ckRBqo8K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [] "
      ],
      "metadata": {
        "id": "Y8083ofxrjXF"
      },
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataset)):\n",
        "  tweet = dataset['OriginalTweet'][i]\n",
        "  tweet = tweet.lower()\n",
        "  tweet = re.sub(r'\\s+',' ',tweet)\n",
        "  tweet = re.sub(r'^[a-zA-Z]',' ',tweet)\n",
        "  corpus.append(tweet)"
      ],
      "metadata": {
        "id": "u2B3GUhdmb1t"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Teu_jn0H8wse",
        "outputId": "53c9c984-8cd9-4e11-aa0b-64c893e5b433"
      },
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@menyrbie @phil_gahan @chrisitv https://t.co/ifz9fan2pa and https://t.co/xx6ghgfzcc and https://t.co/i2nlzdxno8',\n",
              " ' dvice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gp set up online shopping accounts if poss adequate supplies of regular meds but not over order',\n",
              " ' oronavirus australia: woolworths to give elderly, disabled dedicated shopping hours amid covid-19 outbreak https://t.co/binca9vp8p',\n",
              " \" y food stock is not the only one which is empty... please, don't panic, there will be enough food for everyone if you do not take more than you need. stay calm, stay safe. #covid19france #covid_19 #covid19 #coronavirus #confinement #confinementotal #confinementgeneral https://t.co/zrlg0z520j\",\n",
              " \" e, ready to go at supermarket during the #covid19 outbreak. not because i'm paranoid, but because my food stock is litteraly empty. the #coronavirus is a serious thing, but please, don't panic. it causes shortage... #coronavirusfrance #restezchezvous #stayathome #confinement https://t.co/usmualq72n\",\n",
              " ' s news of the regionâ\\x92s first confirmed covid-19 case came out of sullivan county last week, people flocked to area stores to purchase cleaning supplies, hand sanitizer, food, toilet paper and other goods, @tim_dodson reports https://t.co/cfxch7a2lu',\n",
              " ' ashier at grocery store was sharing his insights on #covid_19 to prove his credibility he commented \"i\\'m in civics class so i know what i\\'m talking about\". https://t.co/iefdnehgdo',\n",
              " \" as at the supermarket today. didn't buy toilet paper. #rebel #toiletpapercrisis #covid_19 https://t.co/evxkqlidaz\",\n",
              " ' ue to covid-19 our retail store and classroom in atlanta will not be open for walk-in business or classes for the next two weeks, beginning monday, march 16. we will continue to process online and phone orders as normal! thank you for your understanding! https://t.co/kw91zj5o5i',\n",
              " \" or corona prevention,we should stop to buy things with the cash and should use online payment methods because corona can spread through the notes. also we should prefer online shopping from our home. it's time to fight against covid 19?. #govindia #indiafightscorona\",\n",
              " \" ll month there hasn't been crowding in the supermarkets or restaurants, however reducing all the hours and closing the malls means everyone is now using the same entrance and dependent on a single supermarket. #manila #lockdown #covid2019 #philippines https://t.co/hxws9lanf9\",\n",
              " ' ue to the covid-19 situation, we have increased demand for all food products. the wait time may be longer for all online orders, particularly beef share and freezer packs. we thank you for your patience during this time.',\n",
              " '#horningsea is a caring community. letâ\\x92s all look after the less capable in our village and ensure they stay healthy. bringing shopping to their doors, help with online shopping and self isolation if you have symptoms or been exposed to somebody who has. https://t.co/lsgrxxhjhh',\n",
              " \" e: i don't need to stock up on food, i'll just have amazon deliver whatever i need #coronavirus amazon: https://t.co/8ywakfjexc\",\n",
              " ' dara releases covid-19 resource center for travel brands: insights help travel brands stay up-to-date on consumer travel behavior trends https://t.co/pna797jdkv https://t.co/dqox6usihz',\n",
              " ' ines at the grocery store have been unpredictable, but is eating out a safe alternative? find out more about whether you should be avoiding restaurants right now: https://t.co/9idzsis5oq #coronavirus #covid19 https://t.co/zhbh898lf6',\n",
              " '????? ????? ????? ????? ?? ?????? ????? ??????? ????????? ? #????_???? ????? ???? ?????? ? #????????? ?????? ?? 13 ???? ?? ?? ???? ?????? ?? ?? #???_???????? ????? ??? ???? ? https://t.co/51bl8p6vzh',\n",
              " '@eyeonthearctic 16mar20 russia consumer surveillance watchdog reported case in high arctic where a man who traveled to iran has covid-19 and 101 are \"observed\" https://t.co/4wnrrk9okc https://t.co/ld05k5eyns',\n",
              " ' mazon glitch stymies whole foods, fresh grocery deliveries â\\x93as covid-19 has spread, weâ\\x92ve seen a significant increase in people shopping online for groceries,â\\x94 a spokeswoman said in a statement. â\\x93today this resulted in a systems impact affecting our ... https://t.co/tbzz2mc3b3',\n",
              " \" or those who aren't struggling, please consider donating to a food bank or a nonprofit. the demand for these services will increase as covid-19 impacts jobs, and people's way of life.\",\n",
              " ' ith 100 nations inficted with covid 19 the world must not play fair with china 100 goverments must demand china adopts new guilde lines on food safty the chinese goverment is guilty of being irosponcible with life on a global scale',\n",
              " ' ttps://t.co/avkrr9syff the covid-19 coronavirus pandemic is impacting consumer shopping behavior, purchase decisions and retail sales, according to a first insight study.',\n",
              " ' e have amazing cheap deals! for the #covid2019 going on to help you??? #trials #monthly #yearly and resonable #prices / #subscriptions just dm us! #bestiptv #iptv #service #iptv #iptvdeals #cheap #iptv #football #hd #movies #adult #cinema #hotmovies #iptvnew #iptv2020 #adult',\n",
              " ' e have amazing cheap deals! for the #covid2019 going on to help you??? #trials #monthly #yearly and resonable #prices / #subscriptions just dm us! #bestiptv #iptv #service #iptv #iptvdeals #cheap #iptv #football #hd #movies #adult #cinema #hotmovies #iptv iptvlinks #18movies',\n",
              " '@10downingstreet @grantshapps what is being done to ensure food and other essential products are being re-stocked at supermarkets and panic buying actively discouraged? it cannot be left to checkout staff to police the actions of the selfish and profiteer',\n",
              " \" k #consumer poll indicates the majority expect #covid19's impact to last 4-12 months (at 12 march). we expect this to increase at the next #tracker... see full results of the @retailx coronavirus consumer confidence tracker here: https://t.co/k3ujlcjqdb https://t.co/9g3kgqixj8\",\n",
              " ' n preparation for higher demand and a potential food shortage, the hunger coalition purchased 10 percent more food and implemented new protocols due to the covid-19 coronavirus. https://t.co/5cecytlnyn',\n",
              " ' his morning i tested positive for covid 19. i feel ok, i have no symptoms so far but have been isolated since i found out about my possible exposure to the virus. stay home people and be pragmatic. i will keep you updated on how iâ\\x92m doing ???? no panic. https://t.co/lg7hvmzglz',\n",
              " ' o you see malicious price increases in nyc? the nyc department of consumer and worker protection (dcwp) has set up a page to digitally file a complaint. click here: https://t.co/oex6y8mm2k to file a complaint (use the word\"overcharge\") https://t.co/mdmmobttop #covid19 #covidnyc',\n",
              " '@7sealsoftheend soon with dwindling supplies unlawful panicky people will be breaking into closed stores &amp; supermarkets to raid them as they normally do during a crisis so massive as the #coronavirus #stockup&amp;lockup',\n",
              " ' here is of in the country the more empty shelves people see the more buying ensues the more food is out of stock',\n",
              " \"'hole' foods... ...images from the nicest grocery store in one of the richest neighborhoods in the united states. https://t.co/wnqsomtkvi #breakingnews #breaking #coronavirus #coronavirusoutbreak #covid19 #covid?19 #covid_19 #covid2019 #collapse\",\n",
              " ' etail store closures could explode because of the #coronavirus (via @cnbc). #brickandmortar https://t.co/hqryrnxfhv https://t.co/g5uzn06gb6',\n",
              " ' oronavirus fun fact: if you cough at the grocery store, you get the whole aisle to yourself pretty quickly. #coronavirusoutbreak #coronavirus #covid2019',\n",
              " \" e're sorry to say that our @finfabuk event is being cancelled due to covid-19. the health and wellbeing of our attendees, speakers and staff is our top priority. apologies for any disappointment this may cause. all faqs are answered in the link below: https://t.co/gddptudcvj\",\n",
              " ' ent to the supermarket yesterday and the toilet paper was gone. has this anything to do with the corona virus? #covid2019',\n",
              " \" es, buy only what you need. but what's the point of posting photos of those people in the supermarket with a load of stuff? they could be buying for all their elderly parents, kids, siblings, etc who can't buy for themselves not everything needs to be viral, covid-19 alr is\",\n",
              " ' orried about the impact of the current covid-19 pandemic on your finances? weâ\\x92ve just published some tips to help you manage your money during these challenging times. #covid19 https://t.co/3jkk3cqxfq https://t.co/ebenurmmjs',\n",
              " \" y wife works retail&amp;a customer came in yesterday, coughing everywhere, saying they have covid-19. they requested a deep clean of the store - her company objected to due to cost, recommending the team spray disinfectant&amp;clean themselves. we're gonna die/get sick due to capitalism\",\n",
              " ' ow i can go to the supermarket like this without being judged! ? #coronavirusoutbreak #covid2019 https://t.co/krtcgiuhqs',\n",
              " \" e're here to provide a safe shopping experience for our customers and a healthy environment for our associates and community! online orders can be placed here: https://t.co/dcsxhuj3u0 #jlmco #jlmcobrand #coronapocolypse #coronavirus #coronavirusoutbreak #covid19 #shoponline https://t.co/rinkwskers\",\n",
              " \" urious, do we think retail shoppers will do a lot of online shopping bc they're home and unable to go out or do we think everyone is too spooked to get that extra pair of shoes? #economy #onlineshopping #coronavirus #covid19 #stayhome\",\n",
              " ' heck video ?? https://t.co/1ksn9brl02 ??no food ? in usa market due to coronavirus panic we gonna die from starvation #coronavirusoutbreak #coronavirus #houston #nofood #notoiletpaper #nohandshakes #nohandsanitizer #covid19 #pandemic #totallockdown #covid2019usa #walmart https://t.co/ztn3imkgpd',\n",
              " ' reaking story: online clothes shopping rises as people find mysterious white patches forming on clothes. #quarantinelife #coronavirusoutbreak #coronavirus #imadethisup #fakenews https://t.co/5z24hptt9m',\n",
              " ' his is the line outside @target in as customers wait for the store to open this morning',\n",
              " ' outh africans stock up on food, basic goods as coronavirus panic hits https://t.co/6ngnfjmy89 #coronavirussa #covid_19 https://t.co/pziro10avf',\n",
              " ' please share know someone who s 65 living on their own struggling to get 2 their local supermarket due to issues around 19 we re offering free deliveries of our healthy soups nationwide to anyone 65 in need plus their freezable',\n",
              " ' eople posting and sharing photos of of half to completely empty shelves calling those people \"dumb\" or \"idiots.\" all while shopping at the grocery store. lol #coronavirus #covid19',\n",
              " \" ever thought i'd say this, but. 2019, will you come back!? please! #coronavirus #covid19 #peoplearelosingtheirminds #stopthemadness #stoppanicbuying\",\n",
              " \" ovid-19 restrictions sparking a run on cannabis stores they're not closed yet! but customers are stocking up on cannabis this weekend, preparing for what could be more retail store restrictions in coming days. https://t.co/wmqr8qwoig\",\n",
              " '\"everything weâ\\x92re seeing in the current covid-19 outbreak has been seen before in previous epidemics and pandemics; the rise of fear, racism, panic buying of food and medicines, conspiracy theories, the proliferation of quack cures\" https://t.co/pr8npkx41a',\n",
              " ' veryone is closed, but we remain open because we are an emergency store. thank your retail workers. #covid_19 #pandemic #socialdistancing #retail https://t.co/wtb0b1amon',\n",
              " ' hy we stock up on water... cause utility companies will shut you off in the middle of a pandemic... the schools close thier doors, you lose out on work cause your kid has no where to go... and you canâ\\x92t afford months worth of food. #coronavirus @senatorromney https://t.co/0cv0793ols',\n",
              " \" ear coronavirus, i've been following social distancing rules and staying home to prevent the spread of you. however, now i've spent an alarming amount of money shopping online. where can i submit my expenses to for reimbursement? let me know. #coronapocolypse #coronavirus\",\n",
              " ' lobal food prices before the spread of covid 19 intensified across several geographies we could see further downward pressures in the coming months due to continued well supplied markets and the negative impact on demand resulting from the virus',\n",
              " ' orning everyone have a great and safe day. ??? #coronavirus #stoppanicbuying #bekind #mufc #mufc_family',\n",
              " \" f all the things to panic buy in an emergency, i don't get why toilet paper is so important. if you're afraid of the worst case scenario, just wash up in the tub and use your money on food. y'all crazy. #coronavirus\",\n",
              " ' hank your grocery clerk! went to grocery store today and looked into the weary eyes of the clerk. i thanked her and realized that she was thrust on the front line of this panick. a new breed of first responders? they are working hard to serve their communities. #coronavirus',\n",
              " ' ith the outbreak of covid-19 in entire world, the retail shops in malaysia is facing a great challenges. in the near future, online shopping will be a surprise way for all the people while many will lost their jobs. #malaysia2020 #malaysia #covid?19',\n",
              " ' y thoughts on impacts of coronavirus on food markets https://t.co/bpodddprce',\n",
              " ' onsumer corner: #scammers taking advantage of #covid-19 fears #coronavirus #cdc #flu #trends #alert https://t.co/sk9qcjsnyl https://t.co/t7qejp3hys',\n",
              " '4. \"both the masks made for medical personnel and for consumer purchase require a once-obscure material called melt-blown fabric.\" https://t.co/3hcd9iiwox',\n",
              " ' y work is capitalizing on the demand for packaged food and making us stay open as opposed to closing for all our health and safety #lockdowncanada #coronavirus',\n",
              " ' o, are we feeling like it\\'s ethical to still do stuff like order deliveries (food, online shopping, etc.), ship \"isolation\" care packages to loved ones, etc.? #covid2019',\n",
              " ' hat 2k consumers told pymnts about how covid-19 changed their daily lives https://t.co/ybg8zupdf6 via @pymnts',\n",
              " ' ought a house during covid-19 panic. didnâ\\x92t think to buy food for the house. tragic.',\n",
              " ' een in a facebook group - businesses need to stop increasing prices on essentials while we are in an emergency situation - itâ\\x92s frankly despicable and is totally void community spirit! #nameandshame #covid?19uk #coronavirus #liverpool https://t.co/sttakyqqiz',\n",
              " '@bobjlowe sadly those are the misinformed thinking that covid-19 gives diarrhoea, therefore they had to stock-pile toilet papers. ? atm, hygiene and food are more important.',\n",
              " '@tinamccauley70 yeah my parents are risky people to the covid 19 thatâ\\x92s why we stay at home just go to the supermarket when really necessary.. stay safe too ....',\n",
              " ' n - #coronavirus #covid19 i will be in the group (and so will my mum, who i live with) in the group that needs to be \"shielded\" for 12 weeks (3 months). this will mean staying in. i hope i can still get the online shopping that i need.',\n",
              " ' tâ\\x92s kind of like how saying a word over and over makes it not sound like a word anymore. for many of the people who donâ\\x92t think the covid-19 news is bs, itâ\\x92s making them go to the stores and panic buy food and basic necessities until thereâ\\x92s nothing left.',\n",
              " ' i, covid-19. thanks for making me do more online shopping.',\n",
              " ' orona scare sends sea-food prices skyrocketing in mumbai &gt;&gt; https://t.co/gb11efbyib #seafood #coronavirus #coronavirusoutbreak #coronavirusreachesdelhi #coronavid19 #coronavirusupdates #covid2019 #covid19 #jhalakbollywood #jhalakkollywood #jhalaktollywood https://t.co/u5dg3lofyg',\n",
              " ' ausing student loan payments in addition to halting interest accumulation amp stopping punitive student loan collections would provide much needed immediate relief to those individuals unable to work amp are facing economic hardship',\n",
              " '@balajis on the consumer side - the tech is there (some chinese group already demostrated elisa test strips for covid-19, though details were lacking). for consumer though @us_fda would have to deem it as a waived test, which doesnâ\\x92t come that easily',\n",
              " ' ost wages either due to illness from 19 or to the virus economic impact will mean an increased demand we urge and to support a bill that includes support for food banks flexibility for and school meals and increased',\n",
              " ' he actions of some are so selfish. if i were ceo of a grocery store, from 7-9 am would be a time for people over 65 to shop; show id. i just saw a young couple with 300 rolls of tp. no one is that full of crap. well maybe #coronavirusoutbreak https://t.co/hrbzmh95vq',\n",
              " ' oronavirus poses a complex puzzle for food-delivery companies - their delivery capacity may buckle under surging demand. https://t.co/1c1cmlmqii via @wsj #services #food #delivery #coronavirus',\n",
              " '@thejoshuaturner @loreign83 @peanut_astro @my_amigouk @afneil @borisjohnson @patel4witham this is both disgusting and disgraceful charging over inflated prices for items for stopping the spread of covid-19, the government really needs to do something abou',\n",
              " ' s more retailers close physical stores or curtail hours as a result of covid-19, it is agoing to put additional pressure on other omnichannel alternatives like grocery delivery and curbside pick up. https://t.co/kgydow3nrz #covid19 #ecommerce #omnichannel #retail #digital',\n",
              " ' heck out what these folks are up to here in so cal ? i like this idea ? la habra supermarket offers special hours for seniors amid covid-19 crisis https://t.co/nctxf8tgyf',\n",
              " ' ove it or hate it, head advice @10downingstreet &amp; @borisjohnson blip in our lives but itâ\\x92s happening! ?? donâ\\x92t whinge about what you canâ\\x92t do ?? dont panic buy as food wont run out ?? do spend time with the family ?? do use common sense #coronavirus @worldhealthorg2',\n",
              " ' n open letter to consumer-debt holding organizations and others: we are at the precipice of a crisis of household economy. please suspend debts (and interest/fees) for sixty days in response to the covid-19 crisis. feel free to sign here: https://t.co/jmzzjomnt9 https://t.co/yr2tcpx1ee',\n",
              " '#covid?19 #covid19aus #coronavirus just wanted to spread this news to all older australians, particularly those still mobile but without family support: https://t.co/ydgx4lk8l0',\n",
              " ' adly, this does not surprise me heard from one payer exec that they are laying low, hoping all blows over. mind bogglingly stupid and this was a nonprofit blues plan! https://t.co/zr67d1u12q',\n",
              " '  work in retail i keep stock back for our older customers so when such as frank comes in store for his bread and he sees a empty shelve i say donâ\\x92t worry pal iâ\\x92ve saved you 1. same as pat n her beans. could i get disciplined? yes do i care ? no iâ\\x92ve got a ?? #coronavirus',\n",
              " ' n attempts to lengthen runways marketing budgets are being slashed hiring is being frozen and staffing matrices are being redrawn and dive deep into how consumer startups are battling the impact of on their business',\n",
              " '...â\\x93at this time, our distillery remains in operation, but we will not be offering public tours or hosting functions or events. our retail store is also closed...\" https://t.co/lyzg2kfsm0',\n",
              " \" lease don't hoard food and water. there's absolutely no need to panic buy; the supply chain is completely interrupted. and above all, please don't hoard sanitizing products; there are people out there who really need them, probably more than you. #dontpanicbuy #coronavirus\"]"
            ]
          },
          "metadata": {},
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features = 150, min_df = 3, max_df = 0.6)"
      ],
      "metadata": {
        "id": "YbwCCrTIfI7q"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tfidf.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "UqebP5BQfJse"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset.Sentiment.factorize()[0]\n",
        "y"
      ],
      "metadata": {
        "id": "reTSJkswfMOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "L6njKhWzfRd5"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifierKNN = KNeighborsClassifier(n_neighbors=5)\n",
        "classifierKNN.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "mgzRquf3fOk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16c7c52-e29d-47ce-d109-2b436fa78682"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_knn = classifierKNN.predict(X_test)"
      ],
      "metadata": {
        "id": "giKeqIfwfTrh"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "cm_knn\n",
        "print(\"KNN Accuracy score\", accuracy_score(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "1u2Kv6tAfV4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0b2383-6861-4177-cbd1-a3fd3d0b981e"
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy score 0.4444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample1 = ['Vaccine is best best best best precaution measure']\n",
        "sample2 = ['Vaccine is not helpful always panic']"
      ],
      "metadata": {
        "id": "0ziwgrHSfYkd"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample1 = tfidf.transform(sample1).toarray()\n",
        "sample2 = tfidf.transform(sample2).toarray()"
      ],
      "metadata": {
        "id": "lU6Fr1wnffDM"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment1 = classifierKNN.predict(sample1)\n",
        "sentiment1\n"
      ],
      "metadata": {
        "id": "tSlQKA96fhqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df2ff45-eb58-4475-a915-8f27a16ee002"
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment2 = classifierKNN.predict(sample2)\n",
        "sentiment2"
      ],
      "metadata": {
        "id": "FrlJwWIcfms-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379f8685-2d6d-4ede-fed2-67b3acacfd08"
      },
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Twitter sentiment live prediction**"
      ],
      "metadata": {
        "id": "pbf3DFy2Ieda"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "id": "w07jociMgFxa"
      },
      "outputs": [],
      "source": [
        "import tweepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_key='LEyiXvdcqVd1hOQacbBhvP0Mk'\n",
        "consumer_secret='qqxTIhBfbowDg4xHSsaguJCt4orfhrhfIS6ZKYPBreDAseOrl1'\n",
        "access_token='1515671963376791552-ulGIWc5zJVV2H8tuI13lGfpH2L3Yat'\n",
        "access_secret='Ac2j4UnXtOljvHNcN5nCcICmg9tncV9Celpc3KqB0wVwW'"
      ],
      "metadata": {
        "id": "DA5esVPrvTv-"
      },
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)"
      ],
      "metadata": {
        "id": "uA2o4Dw8qWuB"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = tweepy.API(auth, timeout=20)"
      ],
      "metadata": {
        "id": "PjhtVsJqqwqQ"
      },
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_text = 'vaccine'\n",
        "tweets_list = []"
      ],
      "metadata": {
        "id": "dlOfkpbGq8v6"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for status in tweepy.Cursor(api.search, q = tweet_text, lang = 'en', result_type = 'recent').items(500):\n",
        "      tweets_list.append(status.text)"
      ],
      "metadata": {
        "id": "3F46r9rtrJJX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7143cf09-1688-4b08-b445-2d6e2f05f299"
      },
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TweepError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-414-9fcdb2323373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mtweets_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTweepError\u001b[0m: Twitter error response: status code = 403"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tweets_list)"
      ],
      "metadata": {
        "id": "hP_S4O2ExK2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa720754-b40c-43b5-b657-a0c65bc08487"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tweets_list)):\n",
        "  tweet = re.sub(r'\\W',' ',tweets_list[i])\n",
        "  tweet = re.sub(r'\\s+',' ',tweets_list[i])\n",
        "  tweet = re.sub('[^a-zA-Z]',' ',tweets_list[i])\n",
        "  tweet = tweet.lower()\n",
        "  tweet = tweet.split()\n",
        "  clean_tweet = [ps.stem(word) for word in customer_review if not word in set(stopwords.words('english'))]\n",
        "  clean_tweet = ' '.join(clean_tweets)\n",
        "  tweets_list[i] = clean_tweet"
      ],
      "metadata": {
        "id": "dpr_N9ZfyI1v"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_list[9]"
      ],
      "metadata": {
        "id": "CzcJH0-KgyK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load tf-idf model and text classifier\n"
      ],
      "metadata": {
        "id": "1CQmOihWztW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict live tweets\n",
        "for tweet in twist_list:\n",
        "    sentiment = classifierKNN.predict(tfidf.transform([tweet]).toarray())\n",
        "    if sentiment[0] == 1:\n",
        "      positive_tweet +=1\n",
        "    else:\n",
        "      negative_tweet +=1   "
      ],
      "metadata": {
        "id": "URVRgCmzJesD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}